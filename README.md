# ğŸš€ FLStore: Efficient Federated Learning Storage for Non-Training Workloads

**FLStore** is an innovative **serverless framework** designed to optimize the storage and execution of **non-training workloads** in **Federated Learning (FL)**.

FLStore addresses challenges of **non-training workloads**â€”such as scheduling, debugging, personalization, and clusteringâ€”by dramatically reducing **latency** and **operational costs** through serverless caching and tailored data storage.

âœ… **Performance Highlights:**
- **Latency:** Average reduction of **71%** (peak **99.7%**)
- **Cost:** Average savings of **92.45%** (peak **98.8%**)

FLStore integrates seamlessly into existing FL frameworks with minimal modifications.

---

## ğŸ“¦ Quick Installation

### Quick Setup (Recommended: Ubuntu Linux)

Clone and set up FLStore using a fully automated script:

```bash
git clone https://github.com/SamuelFountain/FLStore
cd FLStore
bash run_example.sh  # Sets up Conda, OpenFaaS, MinIO, downloads data, deploys functions, and runs experiments interactively
```

This script will:
- Install Conda, OpenFaaS, MinIO, and other dependencies (Docker and containerd should be pre-installed).
- Build and deploy experimental data to MinIO.
- Prompt you to select non-training workloads (functions) such as scheduling, debugging, clustering, etc.
- Run selected workloads for a few rounds, print results, and teardown the dev environment.

---

### ğŸ§¹ Cleanup

Use the provided script to clean up resources created by FLStore (especially if using `k3s` and OpenFaaS setup):

```bash
bash cleanup.sh
```

---

### ğŸ“‚ Repository Structure

```plaintext
FLStore/
â”œâ”€â”€ fetch_experiments/     # Scripts to fetch and post FL metadata
â”‚   â”œâ”€â”€ __init__.py        # Python package initialization
â”‚   â”œâ”€â”€ fetch.py           # Data fetching script
â”‚   â””â”€â”€ post.py            # Data posting script
â”œâ”€â”€ run_experiments/       # Experimental evaluation scripts
â”‚   â”œâ”€â”€ __init__.py        # Python package initialization
â”‚   â”œâ”€â”€ experiment1.py     # First experiment script
â”‚   â””â”€â”€ experiment2.py     # Second experiment script
â”œâ”€â”€ serverless/            # Serverless caching and compute functions
â”‚   â”œâ”€â”€ __init__.py        # Python package initialization
â”‚   â”œâ”€â”€ cache.py           # Caching functionality
â”‚   â””â”€â”€ compute.py         # Computation functionality
â”œâ”€â”€ cleanup.sh             # Cleans up resources created by FLStore deployment (including k3s setup)
â”œâ”€â”€ run_example.sh         # Automated setup and execution of FLStore and experiments
â”œâ”€â”€ set_conda.sh           # Optional manual Conda environment setup script
â”œâ”€â”€ README.md              # Project documentation
â”œâ”€â”€ .gitattributes         # Git attributes configuration
â””â”€â”€ .gitignore             # Git ignore configuration
```

---

## ğŸ“Œ Hardware and Software Dependencies

- **Python:** Listed in `environment.yml` and `requirements.txt`
- **Hardware:** Standard server hardware (no specialized equipment required; GPU optional)
- **Software:**
  - Python (via Anaconda)
  - Docker (must be pre-installed)
  - Containerd (recommended)
  - OpenFaaS
  - MinIO or similar object store (for persistent FL metadata storage)

---

## ğŸ“ˆ Benchmarks

| Metric            | Average Reduction | Peak Reduction |
|-------------------|-------------------|----------------|
| Latency           | 71%               | 99.7%          |
| Operational Cost  | 92.45%            | 98.8%          |

Comparisons made against traditional cloud object storage (e.g., AWS S3) and cloud caching solutions (e.g., AWS ElastiCache).

---

## ğŸ“– Citation

Please cite the following if using FLStore:

```bibtex
@misc{khan2025flstore,
  author = {Khan, et al.},
  title = {FLStore: Efficient Federated Learning Storage},
  year = {2025},
  eprint = {2503.00323},
  archivePrefix = {arXiv},
  url = {https://arxiv.org/abs/2503.00323}
}
```

---

## ğŸ¤ Contributions and Communication

Contributions welcome! Submit bugs, features, or improvements via GitHub issues or pull requests.
